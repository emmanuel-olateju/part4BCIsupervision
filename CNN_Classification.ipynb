{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# importations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NeGRTL-e09JM"
      },
      "outputs": [],
      "source": [
        "import pyxdf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from stft import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DFUTCq2RLN8P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['stft', 'ricker', 'y'])\n",
            "(3945, 8, 129, 11) (3945, 8, 15, 1250) 3945\n"
          ]
        }
      ],
      "source": [
        "features = joblib.load('features/time_frequency_features.sav')\n",
        "print(features.keys())\n",
        "print(features['stft'].stft ['Zxx'].shape, features['ricker'].shape, len(features['y']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# splitting dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne51lQ14dGq7",
        "outputId": "0c07926c-b4f3-4d7e-a711-cd8598615795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2761, 8, 15, 1250) (2761,) (1184, 8, 15, 1250) (1184,)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "    use scikit stratified shuffle split method to create train and test dataset\n",
        "    from eeg['morlet_wavelet'] as X and eeg['y'] as y or labels\n",
        "'''\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "\n",
        "ricker_train, ricker_test, y_train, y_test = train_test_split(features['ricker'], np.array(features['y']), test_size=0.3, random_state=42)\n",
        "print(ricker_train.shape, y_train.shape, ricker_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "del X_train,X_test,y_train,y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## after doing all in the above cells, stop here and let me review your CNN knowledge and vhoice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TYUJkMwmT1Px"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import History \n",
        "history = History()\n",
        " \n",
        "img_x = 249\n",
        "img_y = 249\n",
        "img_z = 8\n",
        "input_shape = (img_x, img_y, img_z)\n",
        " \n",
        "# num_classes = 6\n",
        "batch_size = 8\n",
        "num_classes = 7\n",
        "epochs = 3\n",
        " \n",
        "x_train = x_train.astype('float32')\n",
        "X_train = x_train[:-n]\n",
        "X_val = x_train[-n:]\n",
        "\n",
        "x_test = x_test.astype('float32')\n",
        " \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "Y_train = y_train[:-n]\n",
        "Y_val = y_train[-n:]\n",
        "\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PfOdetipWz3v"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kTdv3MX0HMc",
        "outputId": "09bb2b1c-6fd5-4eb2-db4c-1d26af73f290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "250/250 [==============================] - 414s 2s/step - loss: 5.5432e-09 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "250/250 [==============================] - 407s 2s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Train loss: 0.0, Train accuracy: 1.0\n",
            "Test loss: 0.0, Test accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        " \n",
        " \n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=2,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[history])\n",
        " \n",
        "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print('Train loss: {}, Train accuracy: {}'.format(train_score[0], train_score[1]))\n",
        "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: {}, Test accuracy: {}'.format(test_score[0], test_score[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A32ipoTvWW4",
        "outputId": "a75cf6b9-bbd0-4076-a7fd-dec5cdb6418f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 24s 1s/step\n"
          ]
        }
      ],
      "source": [
        "pred = model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Lw8teaoQuy9b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZc-TwD0u-M5",
        "outputId": "ee2e25d1-a2d3-43d0-c825-519409d53528"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# np.argmax(pred, axis=1), np.argmax(Y_val, axis=1)\n",
        "accuracy_score(np.argmax(pred, axis=1), np.argmax(Y_val, axis=1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nij3QthshvXs",
        "outputId": "70f681d3-c3e5-451a-af70-fdd00dea6954"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/keras_CNN_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Syh6C2WckVF8",
        "outputId": "44259369-a134-40ee-836e-a3e4622fc3c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/keras_CNN_model/ (stored 0%)\n",
            "  adding: content/keras_CNN_model/keras_metadata.pb (deflated 90%)\n",
            "  adding: content/keras_CNN_model/saved_model.pb (deflated 88%)\n",
            "  adding: content/keras_CNN_model/assets/ (stored 0%)\n",
            "  adding: content/keras_CNN_model/variables/ (stored 0%)\n",
            "  adding: content/keras_CNN_model/variables/variables.index (deflated 64%)\n",
            "  adding: content/keras_CNN_model/variables/variables.data-00000-of-00001 (deflated 69%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r model.zip /content/keras_CNN_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "v_SEZi4Mh9XY"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5I684FeioqP",
        "outputId": "ebfd0839-1ab2-4c99-c49c-ed207e3e18a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "filename = 'keras_CNN_picklefile'\n",
        "pickle.dump(model, open(filename, \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import keras\n",
        "# from keras.layers import Dense, Flatten\n",
        "# from keras.layers import Conv2D, MaxPooling2D\n",
        "# from keras.models import Sequential\n",
        "# from keras.callbacks import History \n",
        "# history = History()\n",
        " \n",
        "# img_x = 1249\n",
        "# img_y = 1249\n",
        "# img_z = 8\n",
        "# input_shape = (img_x, img_y, img_z)\n",
        " \n",
        "# num_classes = 6\n",
        "# batch_size = 16\n",
        "# num_classes = 7\n",
        "# epochs = 10\n",
        " \n",
        "# x_train = x_train.astype('float32')\n",
        "# x_test = x_test.astype('float32')\n",
        " \n",
        "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        " \n",
        " \n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
        "#                  activation='relu',\n",
        "#                  input_shape=input_shape))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "# model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(1000, activation='relu'))\n",
        "# model.add(Dense(num_classes, activation='softmax'))\n",
        " \n",
        "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#               optimizer=keras.optimizers.Adam(),\n",
        "#               metrics=['accuracy'])\n",
        " \n",
        " \n",
        "# model.fit(x_train, y_train,\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           verbose=1,\n",
        "#           validation_data=(x_test, y_test),\n",
        "#           callbacks=[history])\n",
        " \n",
        "# train_score = model.evaluate(x_train, y_train, verbose=0)\n",
        "# print('Train loss: {}, Train accuracy: {}'.format(train_score[0], train_score[1]))\n",
        "# test_score = model.evaluate(x_test, y_test, verbose=0)\n",
        "# print('Test loss: {}, Test accuracy: {}'.format(test_score[0], test_score[1]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('DL_Keras')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "5aba0adc9b334b1997a0335f731b2a1d1b803be1f0eea858c81e564f0a4ac976"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
